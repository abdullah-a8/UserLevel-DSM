"""CSV reader for DSM statistics files.

Reads the CSV files generated by the DSM perf_log module:
- dsm_stats_nodeN.csv: Per-node statistics summary
- perf_log.csv: Detailed event log with timestamps

File formats (from perf_log.c):

dsm_stats_nodeN.csv:
    metric,value
    node_id,0
    page_faults,123
    read_faults,100
    write_faults,23
    ...

perf_log.csv:
    timestamp_ns,event_type,page_id,access_type,latency_ns,was_queued
    1234567890,PAGE_FAULT,42,READ,1500,0
    ...
"""

import csv
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional

from dsm_visualizer.models.dsm_stats import DSMStats, NodeStats


@dataclass
class PerfEvent:
    """A single performance event from perf_log.csv."""

    timestamp_ns: int
    event_type: str  # PAGE_FAULT, FALSE_SHARING
    page_id: int
    access_type: str  # READ, WRITE, NA
    latency_ns: int
    was_queued: bool


class CSVStatsReader:
    """
    Reads DSM statistics CSV files generated after a run.

    Files are named: dsm_stats_node{N}.csv
    Format: metric,value (key-value pairs)
    """

    def __init__(self, stats_dir: str = "."):
        """
        Initialize the CSV stats reader.

        Args:
            stats_dir: Directory containing the stats CSV files.
        """
        self.stats_dir = Path(stats_dir)

    def read_node_stats(self, node_id: int) -> Optional[NodeStats]:
        """
        Read statistics for a specific node.

        Args:
            node_id: The node ID to read stats for.

        Returns:
            NodeStats object or None if file not found.
        """
        stats_file = self.stats_dir / f"dsm_stats_node{node_id}.csv"

        if not stats_file.exists():
            return None

        stats = NodeStats(node_id=node_id)

        try:
            with open(stats_file, "r") as f:
                reader = csv.DictReader(f)
                for row in reader:
                    metric = row.get("metric", "")
                    value_str = row.get("value", "0")

                    try:
                        value = int(value_str)
                    except ValueError:
                        continue

                    # Map CSV metrics to NodeStats fields
                    if metric == "page_faults":
                        stats.page_faults = value
                    elif metric == "read_faults":
                        stats.read_faults = value
                    elif metric == "write_faults":
                        stats.write_faults = value
                    elif metric == "pages_fetched":
                        stats.pages_fetched = value
                    elif metric == "pages_sent":
                        stats.pages_sent = value
                    elif metric == "invalidations_sent":
                        stats.invalidations_sent = value
                    elif metric == "invalidations_received":
                        stats.invalidations_received = value
                    elif metric == "network_bytes_sent":
                        stats.bytes_sent = value
                    elif metric == "network_bytes_received":
                        stats.bytes_received = value
                    elif metric == "total_fault_latency_ns":
                        stats.total_fault_latency_ns = value
                    elif metric == "max_fault_latency_ns":
                        stats.max_fault_latency_ns = value
                    elif metric == "min_fault_latency_ns":
                        stats.min_fault_latency_ns = value

            return stats

        except Exception as e:
            print(f"Error reading {stats_file}: {e}")
            return None

    def read_all_nodes(self, num_nodes: int) -> DSMStats:
        """
        Read statistics for all nodes.

        Args:
            num_nodes: Total number of nodes to read.

        Returns:
            DSMStats object containing all node statistics.
        """
        dsm_stats = DSMStats()

        for node_id in range(num_nodes):
            node_stats = self.read_node_stats(node_id)
            if node_stats:
                dsm_stats.set_node(node_id, node_stats)

        return dsm_stats

    def find_stats_files(self) -> List[int]:
        """
        Find all available node stats files in the directory.

        Returns:
            List of node IDs that have stats files.
        """
        node_ids = []
        for f in self.stats_dir.glob("dsm_stats_node*.csv"):
            try:
                # Extract node ID from filename
                node_id = int(f.stem.replace("dsm_stats_node", ""))
                node_ids.append(node_id)
            except ValueError:
                continue
        return sorted(node_ids)


class PerfLogReader:
    """
    Reads detailed performance event logs from perf_log.csv.

    Format: timestamp_ns,event_type,page_id,access_type,latency_ns,was_queued
    """

    def __init__(self, log_file: str = "perf_log.csv"):
        """
        Initialize the perf log reader.

        Args:
            log_file: Path to the perf_log.csv file.
        """
        self.log_file = Path(log_file)

    def read_events(self) -> List[PerfEvent]:
        """
        Read all events from the log file.

        Returns:
            List of PerfEvent objects.
        """
        if not self.log_file.exists():
            return []

        events = []

        try:
            with open(self.log_file, "r") as f:
                reader = csv.DictReader(f)
                for row in reader:
                    try:
                        event = PerfEvent(
                            timestamp_ns=int(row.get("timestamp_ns", 0)),
                            event_type=row.get("event_type", ""),
                            page_id=int(row.get("page_id", 0)),
                            access_type=row.get("access_type", "NA"),
                            latency_ns=int(row.get("latency_ns", 0)),
                            was_queued=row.get("was_queued", "0") == "1",
                        )
                        events.append(event)
                    except (ValueError, KeyError):
                        continue

        except Exception as e:
            print(f"Error reading {self.log_file}: {e}")

        return events

    def get_page_faults(self) -> List[PerfEvent]:
        """Get only PAGE_FAULT events."""
        return [e for e in self.read_events() if e.event_type == "PAGE_FAULT"]

    def get_false_sharing_events(self) -> List[PerfEvent]:
        """Get only FALSE_SHARING events."""
        return [e for e in self.read_events() if e.event_type == "FALSE_SHARING"]

    def get_events_by_time_range(self, start_ns: int, end_ns: int) -> List[PerfEvent]:
        """
        Get events within a time range.

        Args:
            start_ns: Start timestamp in nanoseconds.
            end_ns: End timestamp in nanoseconds.

        Returns:
            List of events in the time range.
        """
        return [e for e in self.read_events() if start_ns <= e.timestamp_ns <= end_ns]
